{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "\n",
    "# Vector Representations\n",
    "## *Data Science Unit 4 Sprint 2 Assignment 2*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 159
    },
    "colab_type": "code",
    "id": "hyj-f9FDcVFp",
    "outputId": "5dd045fe-6e4c-458c-e2fc-253c3da9c805"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "import os\n",
    "\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M7bcmqfGXrFG"
   },
   "source": [
    "## 1) *Clean:* Job Listings from indeed.com that contain the title \"Data Scientist\" \n",
    "\n",
    "You have `job_listings.csv` in the data folder for this module. The text data in the description column is still messy - full of html tags. Use the [BeautifulSoup](https://www.crummy.com/software/BeautifulSoup/bs4/doc/) library to clean up this column. You will need to read through the documentation to accomplish this task. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KcYlc1URXhlC"
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "##### Your Code Here #####\n",
    "\n",
    "# get our data\n",
    "df0 = pd.read_csv(\"data/job_listings.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>description</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>b\"&lt;div&gt;&lt;div&gt;Job Requirements:&lt;/div&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;...</td>\n",
       "      <td>Data scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>b'&lt;div&gt;Job Description&lt;br/&gt;\\n&lt;br/&gt;\\n&lt;p&gt;As a Da...</td>\n",
       "      <td>Data Scientist I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>b'&lt;div&gt;&lt;p&gt;As a Data Scientist you will be work...</td>\n",
       "      <td>Data Scientist - Entry Level</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>b'&lt;div class=\"jobsearch-JobMetadataHeader icl-...</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>b'&lt;ul&gt;&lt;li&gt;Location: USA \\xe2\\x80\\x93 multiple ...</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                        description  \\\n",
       "0           0  b\"<div><div>Job Requirements:</div><ul><li><p>...   \n",
       "1           1  b'<div>Job Description<br/>\\n<br/>\\n<p>As a Da...   \n",
       "2           2  b'<div><p>As a Data Scientist you will be work...   \n",
       "3           3  b'<div class=\"jobsearch-JobMetadataHeader icl-...   \n",
       "4           4  b'<ul><li>Location: USA \\xe2\\x80\\x93 multiple ...   \n",
       "\n",
       "                          title  \n",
       "0               Data scientist   \n",
       "1              Data Scientist I  \n",
       "2  Data Scientist - Entry Level  \n",
       "3                Data Scientist  \n",
       "4                Data Scientist  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Doing this so if I mess up the dataframe, I can just rerun this\n",
    "\n",
    "df = df0.copy()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_description(desc):\n",
    "    soup = BeautifulSoup(desc)\n",
    "    text = soup.get_text()\n",
    "    if text[0] == \"b\":\n",
    "        text=text[1:]\n",
    "    return text.replace(\"\\\\n\", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['description'] = df0['description'].apply(clean_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>description</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>\"Job Requirements: Conceptual understanding in...</td>\n",
       "      <td>Data scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>'Job Description  As a Data Scientist 1, you w...</td>\n",
       "      <td>Data Scientist I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>'As a Data Scientist you will be working on co...</td>\n",
       "      <td>Data Scientist - Entry Level</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>'$4,969 - $6,756 a monthContractUnder the gene...</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>'Location: USA \\xe2\\x80\\x93 multiple locations...</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                        description  \\\n",
       "0           0  \"Job Requirements: Conceptual understanding in...   \n",
       "1           1  'Job Description  As a Data Scientist 1, you w...   \n",
       "2           2  'As a Data Scientist you will be working on co...   \n",
       "3           3  '$4,969 - $6,756 a monthContractUnder the gene...   \n",
       "4           4  'Location: USA \\xe2\\x80\\x93 multiple locations...   \n",
       "\n",
       "                          title  \n",
       "0               Data scientist   \n",
       "1              Data Scientist I  \n",
       "2  Data Scientist - Entry Level  \n",
       "3                Data Scientist  \n",
       "4                Data Scientist  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5C4xFZNtX1m2"
   },
   "source": [
    "## 2) Use Spacy to tokenize the listings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dhUHuMr-X-II"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done 1\n",
      "done 2\n"
     ]
    }
   ],
   "source": [
    "print(\"done 1\")\n",
    "\n",
    "# load spacy datamodel\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "\n",
    "print(\"done 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['job', 'requirement', 'conceptual', 'understanding', 'Machine', 'Learning', 'model', 'like', 'nai\\\\xc2\\\\xa8ve', 'Bayes', 'K', 'Means', 'SVM', 'Apriori', 'Linear/', 'Logistic', 'Regression', 'neural', 'Random', 'Forests', 'decision', 'Trees', 'K', 'NN', 'hand', 'experience', '2', 'Intermediate', 'expert', 'level', 'coding', 'skill', 'Python', 'R.', 'ability', 'write', 'function', 'clean', 'efficient', 'datum', 'manipulation', 'mandatory', 'role', 'exposure', 'package', 'like', 'NumPy', 'SciPy', 'Pandas', 'Matplotlib', 'etc', 'Python', 'GGPlot2', 'dplyr', 'tidyR', 'r', 'ability', 'communicate', 'Model', 'finding', 'Technical', 'Non', 'technical', 'stake', 'holder', 'hand', 'experience', 'SQL', 'Hive', 'similar', 'programming', 'language', 'past', 'work', 'GitHub', 'Kaggle', 'publish', 'article', 'Master', 'degree', 'Statistics', 'Mathematics', 'Computer', 'Science', 'quant', 'specific', 'field', 'apply']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nfor token in q2:\\n    print(token)\\n'"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add some stop words\n",
    "\n",
    "new_stop_words = []\n",
    "\n",
    "STOPS = nlp.Defaults.stop_words.union(new_stop_words)\n",
    "\n",
    "#print(\"Added\", new_stop_words, \"to stop words\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['job', 'requirement', 'conceptual', 'understanding', 'Machine', 'Learning', 'model', 'like', 'nai\\\\xc2\\\\xa8ve', 'Bayes', 'K', 'Means', 'SVM', 'Apriori', 'Linear/', 'Logistic', 'Regression', 'neural', 'Random', 'Forests', 'decision', 'Trees', 'K', 'NN', 'hand', 'experience', '2', 'Intermediate', 'expert', 'level', 'coding', 'skill', 'Python', 'R.', 'ability', 'write', 'function', 'clean', 'efficient', 'datum', 'manipulation', 'mandatory', 'role', 'exposure', 'package', 'like', 'NumPy', 'SciPy', 'Pandas', 'Matplotlib', 'etc', 'Python', 'GGPlot2', 'dplyr', 'tidyR', 'r', 'ability', 'communicate', 'Model', 'finding', 'Technical', 'Non', 'technical', 'stake', 'holder', 'hand', 'experience', 'SQL', 'Hive', 'similar', 'programming', 'language', 'past', 'work', 'GitHub', 'Kaggle', 'publish', 'article', 'Master', 'degree', 'Statistics', 'Mathematics', 'Computer', 'Science', 'quant', 'specific', 'field', 'apply']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nfor token in q2:\\n    print(token)\\n'"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# function for getting lemmas for a given text\n",
    "# will be used with .apply() to get lemmas for entire dataframe\n",
    "\n",
    "def tokenizer(text):\n",
    "    \n",
    "    #pacy_tokenizer = Tokenizer(nlp.vocab)\n",
    "    #oc = spacy_tokenizer(text)\n",
    "    \n",
    "    lemmas = []\n",
    "    \n",
    "    doc = nlp(text)\n",
    "    \n",
    "    for token in doc: \n",
    "        if ((token.text.lower() not in STOPS) and (token.is_punct == False)) and (token.pos_ != 'PRON'):\n",
    "            lemmas.append(token.lemma_)\n",
    "        \n",
    "    return lemmas\n",
    "\n",
    "q2 = tokenizer(df['description'][0])\n",
    "print(q2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Job \t \"Job\n",
      "Requirements: \t Requirements:\n",
      "Conceptual \t Conceptual\n",
      "understanding \t understanding\n",
      "in \t in\n",
      "Machine \t Machine\n",
      "Learning \t Learning\n",
      "models \t models\n",
      "like \t like\n",
      "Nai\\xc2\\xa8ve \t Nai\\xc2\\xa8ve\n",
      "Bayes, \t Bayes,\n",
      "K-Means, \t K-Means,\n",
      "SVM, \t SVM,\n",
      "Apriori, \t Apriori,\n",
      "Linear/ \t Linear/\n",
      "Logistic \t Logistic\n",
      "Regression, \t Regression,\n",
      "Neural, \t Neural,\n",
      "Random \t Random\n",
      "Forests, \t Forests,\n",
      "Decision \t Decision\n",
      "Trees, \t Trees,\n",
      "K-NN \t K-NN\n",
      "along \t along\n",
      "with \t with\n",
      "hands-on \t hands-on\n",
      "experience \t experience\n",
      "in \t in\n",
      "at \t at\n",
      "least \t least\n",
      "2 \t 2\n",
      "of \t of\n",
      "them \t them\n",
      "Intermediate \t Intermediate\n",
      "to \t to\n",
      "expert \t expert\n",
      "level \t level\n",
      "coding \t coding\n",
      "skills \t skills\n",
      "in \t in\n",
      "Python/R. \t Python/R.\n",
      "(Ability \t (Ability\n",
      "to \t to\n",
      "write \t write\n",
      "functions, \t functions,\n",
      "clean \t clean\n",
      "and \t and\n",
      "efficient \t efficient\n",
      "data \t data\n",
      "manipulation \t manipulation\n",
      "are \t are\n",
      "mandatory \t mandatory\n",
      "for \t for\n",
      "this \t this\n",
      "role) \t role)\n",
      "Exposure \t Exposure\n",
      "to \t to\n",
      "packages \t packages\n",
      "like \t like\n",
      "NumPy, \t NumPy,\n",
      "SciPy, \t SciPy,\n",
      "Pandas, \t Pandas,\n",
      "Matplotlib \t Matplotlib\n",
      "etc \t etc\n",
      "in \t in\n",
      "Python \t Python\n",
      "or \t or\n",
      "GGPlot2, \t GGPlot2,\n",
      "dplyr, \t dplyr,\n",
      "tidyR \t tidyR\n",
      "in \t in\n",
      "R \t R\n",
      "Ability \t Ability\n",
      "to \t to\n",
      "communicate \t communicate\n",
      "Model \t Model\n",
      "findings \t findings\n",
      "to \t to\n",
      "both \t both\n",
      "Technical \t Technical\n",
      "and \t and\n",
      "Non-Technical \t Non-Technical\n",
      "stake \t stake\n",
      "holders \t holders\n",
      "Hands \t Hands\n",
      "on \t on\n",
      "experience \t experience\n",
      "in \t in\n",
      "SQL/Hive \t SQL/Hive\n",
      "or \t or\n",
      "similar \t similar\n",
      "programming \t programming\n",
      "language \t language\n",
      "Must \t Must\n",
      "show \t show\n",
      "past \t past\n",
      "work \t work\n",
      "via \t via\n",
      "GitHub, \t GitHub,\n",
      "Kaggle \t Kaggle\n",
      "or \t or\n",
      "any \t any\n",
      "other \t other\n",
      "published \t published\n",
      "article \t article\n",
      "Master's \t Master's\n",
      "degree \t degree\n",
      "in \t in\n",
      "Statistics/Mathematics/Computer \t Statistics/Mathematics/Computer\n",
      "Science \t Science\n",
      "or \t or\n",
      "any \t any\n",
      "other \t other\n",
      "quant \t quant\n",
      "specific \t specific\n",
      "field. \t field.\n",
      "Apply \t Apply\n",
      "Now\" \t Now\"\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.doc.Doc"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-lgCZNL_YycP"
   },
   "source": [
    "## 3) Use Scikit-Learn's CountVectorizer to get word counts for each listing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X2PZ8Pj_YxcF"
   },
   "outputs": [],
   "source": [
    "##### Your Code Here #####\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vect = CountVectorizer(stop_words='english', max_features=1000)\n",
    "\n",
    "#Learn our Vocab\n",
    "vect.fit(data)\n",
    "\n",
    "# Get sparse dtm\n",
    "dtm = vect.transform(df['description'])\n",
    "\n",
    "dtm = pd.DataFrame(dtm.todense(), columns=vect.get_feature_names())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Zo1iH_UeY7_n"
   },
   "source": [
    "## 4) Visualize the most common word counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M5LB00uyZKV5"
   },
   "outputs": [],
   "source": [
    "##### Your Code Here #####\n",
    "raise Exception(\"\\nThis task is not complete. \\nReplace this line with your code for the task.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bwFsTqrVZMYi"
   },
   "source": [
    "## 5) Use Scikit-Learn's tfidfVectorizer to get a TF-IDF feature matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-gx2gZCbl5Np"
   },
   "outputs": [],
   "source": [
    "##### Your Code Here #####\n",
    "raise Exception(\"\\nThis task is not complete. \\nReplace this line with your code for the task.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Create a NearestNeighbor Model. Write the description of your ideal datascience job and query your job listings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "##### Your Code Here #####\n",
    "raise Exception(\"\\nThis task is not complete. \\nReplace this line with your code for the task.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FiDfTWceoRkH"
   },
   "source": [
    "## Stretch Goals\n",
    "\n",
    " - Try different visualizations for words and frequencies - what story do you want to tell with the data?\n",
    " - Scrape Job Listings for the job title \"Data Analyst\". How do these differ from Data Scientist Job Listings\n",
    " - Try and identify requirements for experience specific technologies that are asked for in the job listings. How are those distributed among the job listings?\n",
    " - Use a clustering algorithm to cluster documents by their most important terms. Do the clusters reveal any common themes?\n",
    "  - **Hint:** K-means might not be the best algorithm for this. Do a little bit of research to see what might be good for this. Also, remember that algorithms that depend on Euclidean distance break down with high dimensional data.\n",
    " - Create a labeled dataset - which jobs will you apply for? Train a model to select the jobs you are most likely to apply for. :) "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "LS_DS_422_BOW_Assignment.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "U4-S1-NLP (Python3)",
   "language": "python",
   "name": "u4-s1-nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "nteract": {
   "version": "0.14.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
